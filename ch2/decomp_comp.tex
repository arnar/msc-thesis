\section{Decomposing Computations} % (fold)
\label{sec:decomp_comp}

We seek a definition of a \emph{formula quotient w.r.t. a process/state}
following the work of~\cite{Larsen91}.
This might be written as $\phi / p$ where $\phi$ is an \HMLpast{} formula
and $p$ is a process. The theorem we then seek to prove is this:
\[
    p \parallel q \vDash \phi  \quad\Leftrightarrow\quad p \vDash \phi / q
\]
where the \emph{parallel composition operator $\parallel$} is suitably defined
over LTSs.

Given our definition of $\vDash$ for \HMLpast, this requires us to prove
a theorem of the form
\[
    \rho \vDash \phi  \quad\Leftrightarrow\quad \rho_1 \vDash \phi / \rho_2
\]
where $\rho,\rho_1,\rho_2$ are computations such that $\rho$ is 
a computation of a process of the form $p \parallel q$ and that is,
in some sense,
the ``parallel composition'' of $\rho_1$ and $\rho_2$. In the 
standard setting it is straightforward to identify the components of a
parallel composition. In the case of computations, however, this is not so
obvious. A computation composed of two processes run in parallel has the form
\[
    (p\parallel q, \pi)
\]
where $p\parallel q$ is a syntactic representation of the initial state and
$\pi$ is the path leading up to the current state. The path $\pi$ however
may involve contributions from both of the parallel components.
Separating the contributions of the components
for the purposes of decompositional model checking requires us to \emph{unzip}
these paths into separate paths that might have been observed by considering
only one argument of the composition. This means that we have to find two paths $\pi_p$
and $\pi_q$ such that the computations
\[
    (p, \pi_p) \quad\textrm{and}\quad (q, \pi_q)
\]
are in some sense independent computations that run in parallel will
yield \mbox{$(p\parallel q, \pi)$}.

% subsection the_theorem_we_seek (end)

\subsection{Decomposition of computations} % (fold)
\label{sub:decomposition_of_computations}

In the setting of HML without past, parallel composition may be defined 
directly on LTSs independent
of the syntax or semantics of the underlying process algebra. When dealing
with computations, this does not provide enough information to find the two
computations that make up the parallel composition. For this information, one
needs to look into the syntax and semantics of the processes themselves and
moreover their semantics have to follow some restrictions.

For this study, 
in order to highlight the main ideas and technical tools in our approach,
we will restrict ourselves to a subset of CCS, namely CCS without
renaming, restriction or recursion. 
(We will discuss possible extensions of our results in 
Section~\ref{sec:decomp_future}.)
Processes are thus defined by the following
grammar.
\[
    p,q \quad::=\quad 0 \alt \alpha.p \alt p + q \alt p \parallel q
\]
with the following operational semantics
\begin{gather*}
    \sosrule{}{\alpha.p \trans{\alpha} p} \qquad
    \sosrule{p\trans{\alpha}p'}{p + q \trans{a} p'} \qquad
    \sosrule{q\trans{\alpha}q'}{p + q \trans{a} q'} \\
    \sosrule{p\trans{\alpha}p'}{p \parallel q \trans{\alpha} p' \parallel q} \qquad
    \sosrule{q\trans{\alpha}q'}{p \parallel q \trans{\alpha} p \parallel q'} \qquad
    \sosrule{p\trans{a}p'\quad q\trans{\bar{a}}q'}{p \parallel q \trans{\tau} p' \parallel q'}
\end{gather*}
We write $p\trans{\alpha}q$ to denote that this transition is provable by
these rules. We assume also that $\bar{\cdot} : A\rightarrow A$ is a function on action names
such that $\bar{\bar{a}} = a$.
The LTS associated with a CCS process $p$ is the largest transition system 
generated by these
rules starting from the process $p$. 
%We will use the notation $\C(p)$ to represent the set of computations in the
%LTS associated with $p$.

The decomposition of a computation running two parallel components must retain the
information about the order of steps in the interleaved computation. We do this
by modelling the decomposition using {\em stuttering computations}. These are
computations that are not only sequences of transition triplets, but may also involve
pseudo steps labelled with $\ptrans{}$. Intuitively, $p\ptrans{} p$ means that
process $p$ has remained idle in the last transition performed by a parallel process
having $p$ as one of its parallel components.
We denote
the set of stuttering computations with $\C_\T^*$ or simply $\C^*$.
For example, the computation
\[
(a.0\parallel b.0,
a.0\parallel b.0 \trans{a}
0\parallel b.0 \trans{b}
0\parallel 0)
\]
is decomposed into the stuttering computations
\begin{gather*}
    (a.0,a.0 \trans{a}0 \ptrans{}0) \quad\textrm{and}\\
    (b.0,b.0 \ptrans{} b.0 \trans{b} 0).\quad\phantom{\textrm{and}}
\end{gather*}
%
% However, we must be careful when decomposing computations that
% already involve stuttering steps.
% In this case we must tag the stuttering steps appropriately in order to prevent ambiguities.
% For example, consider the following computation.
% \[
% ((a.0\parallel b.0) \parallel c.0,\
%  (a.0\parallel b.0) \parallel c.0 \trans{a}
%  (0 \parallel b.0) \parallel c.0 \trans{b}
%  (0 \parallel 0) \parallel c.0 \trans{c}
%  (0 \parallel 0) \parallel 0)
% \]
% We first decompose this into
% \begin{gather*}
% (a.0\parallel b.0,\
% a.0\parallel b.0 \trans{a}
% 0\parallel b.0 \trans{b}
% 0\parallel 0 \ptrans{}
% 0\parallel 0)
% \\
% (c.0,\ c.0 \ptrans{} c.0 \ptrans{} c.0 \trans{c} 0)
% \end{gather*}
% Now we must decompose the first computation further, but it is already stuttering.
% To indicate at which decomposition step the stuttering steps are introduced,
% we tag them with a natural number. When decomposing a computation that is not
% stuttering, all stuttering steps get tagged with $0$, denoted by $\ptrans 0$. This is what
% we have simply called $\ptrans{}$ until now. When decomposing a computation that
% is already stuttering, new stuttering steps are also labelled with 
% $\ptrans 0$ but any existing
% stuttering steps coming from the composed computation
% have their tag increased by one.
% Returning to our example, which with tagged stuttering steps is
% \begin{gather*}
% (a.0\parallel b.0,\
% a.0\parallel b.0 \trans{a}
% 0\parallel b.0 \trans{b}
% 0\parallel 0 \ptrans{0}
% 0\parallel 0),
% \\
% (c.0,\ c.0 \ptrans{0} c.0 \ptrans{0} c.0 \trans{c} 0).
% \end{gather*}
% Its decomposition is
% \begin{gather*}
%     (a.0,\ a.0 \trans{a} 0 \ptrans{0} 0 \ptrans{1} 0) \\
%     (b.0,\ b.0 \ptrans{0} b.0 \trans{b} 0 \ptrans{1} 0) \\
%     (c.0,\ c.0 \ptrans{1} c.0 \ptrans{1} c.0 \trans{c} 0)
% \end{gather*}
%
However, the decomposition of a parallel computation 
is not in general unique, as there may be several possibilities
stemming from different synchronisation patterns.
For example consider a computation with the following trace.
\[
     (a.0+b.0)\parallel(\bar{a}.0+\bar{b}.0) \trans{\tau} 0\parallel 0
\]
From this computation it is not possible to distinguish if the transition
labelled with $\tau$ was the result of communication of the $a$ and $\bar a$ actions,
or of the $b$ and $\bar b$ actions.
For our purposes, this is not necessarily a problem because no expression
of our logic can differentiate between the two synchronisations, given only the composed
computation. We thus consider all possibilities simultaneously,
i.e. a decomposition of a computation will actually
be \emph{a set} of pairs of components.

The following function over paths defines the decomposition of a computation.
%To define the possible decompositions of a computation of the form $(p\parallel q, \pi)$
%we define the following function on paths.
\begin{align*}
    D(\lambda) &= \{(\lambda,\lambda)\} \\
    D(\pi'(p'\parallel q' \ptrans{} p'\parallel q')) &=
        \{(\mu_1(p'\ptrans{}p'),\mu_2(q'\ptrans{}q')) \alt (\mu_1,\mu_2)\in D(\pi')\} \\
    D(\pi'(p'\parallel q' \trans{\alpha} p''\parallel q'')) &=
        \begin{cases}
            \{(\mu_1(p' \trans{\alpha} p''), \mu_2(q' \ptrans{} q')) \\ \quad\quad
                \alt (\mu_1,\mu_2) \in D(\pi')\} & \textrm{if $q'\equiv q''$} \\[0.7em]
            \{(\mu_1(p' \ptrans{} p'), \mu_2(q'\trans{\alpha} q'')) \\ \quad\quad
                \alt (\mu_1,\mu_2) \in D(\pi')\} & \textrm{if $p'\equiv p''$} \\[0.7em]
            \{(\mu_1(p'\trans{a}p''), \mu_2(q'\trans{\bar{a}}q'')) \\ \quad\quad
                \alt (\mu_1,\mu_2) \in D(\pi'), a\in A, \\
                \qquad\qquad p'\trans{a}p'', q'\trans{\bar{a}}q''\}
                & \textrm{otherwise and $\alpha=\tau$}
        \end{cases}
\end{align*}
We should make a note of the fact that if $(\mu_1,\mu_2)$ is a decomposition
of a computation $\pi$, then the three computations have the same length.
Furthermore
\begin{equation}\label{eq:last_equals_last}
    \last(\pi) = \last(\mu_1) \parallel \last(\mu_2).
\end{equation}
%
Also of interest
is that, even though the above definition yields a set of decompositions of $\pi$, the only
case where multiple possibilities are generated is the last case where both components
evolve, and where there is ambiguity in the processes as to which actions actually
contributed to the communication. As we mentioned above, there is no expression
of the \HMLpast{} logic that can resolve such ambiguity only by looking at a composed
computation.
Since our goal is to model check of such expressions, the
existence of multiple decompositions of one computation will not pose any problem.
%Looking at a $\tau$ step in a composed computation, the computation does
%may not contain enough information to see precisely which actions were performed
%by each component. 
%Consider again the trace
%\[
%     (a.0+b.0)\parallel(\bar{a}.0+\bar{b}.0) \trans{\tau} 0\parallel 0
%\]
%In this case it is impossible to tell if the $\tau$ step is a result of matching
%$a$ with $\bar{a}$ or of matching $b$ with $\bar{b}$. 
%In reality, one or the other
%must have happened, but since the result is identical we cannot tell which.
%While this ambiguity may seem problematic at first, we note that no expression
%of \HMLpast{} logic can differentiate between the two ``realities'' only by looking
%at a composed computation.

Another notable property of path decomposition, is that its inverse is unique, i.e.
a pair $(\mu_1,\mu_2)$ can only be the decomposition of a single path. We formalise
this as a lemma which will come in handy later.
\begin{lemma}\label{thm:paths_compose_uniquely}
    Let $\pi_1$ be a path of a parallel computation and $(\mu_1,\mu_2)\in D(\pi_1)$. 
    If $\pi_2$ is a path such
    that $(\mu_1,\mu_2)\in D(\pi_2)$ also, then $\pi_1=\pi_2$.
\end{lemma}
\begin{proof}
    We start by noting that $\pi_1$ and $\pi_2$ cannot differ in length, as they
    are both equal in length to $\mu_1$ (and $\mu_2$). We apply induction on
    their common length.

    If both are empty, $\pi_1=\pi_2=\lambda$, then there is nothing to prove.
    Now assume they are non-empty and that
    \begin{align*}
        \pi_1 &= \pi_1' (p_1' \parallel q_1' \ R_1\  p_1 \parallel q_1) \\
        \pi_2 &= \pi_2' (p_2' \parallel q_2' \ R_2\  p_2 \parallel q_2)
    \end{align*}
    where $R_1,R_2$ are relations of the form $\trans\alpha$ or $\ptrans{}$.
    The induction hypothesis states that $\pi_1' = \pi_2'$, which also means
    that $p_1'=p_2'$ and $q_1'=q_2'$. Property~\eqref{eq:last_equals_last} above
    furthermore gives that $p_1=p_2$ and $q_1=q_2$.
    Thus we only need to show
    that the final steps coincide also, i.e. that $R_1=R_2$.
    % and the processes
    % $p_1, q_1$ are equal to $p_2,q_2$, respectively.
    The proof proceeds by case analysis on the last steps of $\mu_1$ and $\mu_2$.    
    \begin{itemize}
        \item If both $\mu_1$ and $\mu_2$ end with a pseudo-step, then we see from the definition
        of $D$ that both $R_1$ and $R_2$ must be pseudo-transitions. 
        % Since processes do
        %     not evolve during such transitions, it is obvious that $p_1,q_1$ are respectively
        %     equal to $p_2,q_2$.
        
        \item If only one of $\mu_1$ and $\mu_2$ ends with a pseudo-step, then the action
        of the other one must be the same as the last action of both $\pi$ and $\pi'$.
        % Since the transition system for CCS is deterministic for a fixed label, it
        % follows that the right hand sides of the last transitions are also equal.
        
        \item If both $\mu_1$ and $\mu_2$ end with a proper transition, we note that by
        the definition of $D$ the actions must complement each other. Then
        the last step of both $\pi$ and $\pi'$ must thus be labelled with $\tau$.
        % and by the same argument as before the right hand sides must match.
        
        \item If both $\mu_1$ and $\mu_2$ end with a proper transition, we note that by
        the definition of $D$ the actions must complement each other. Then
        the last step of both $\pi$ and $\pi'$ must thus be labelled with $\tau$.
        % and by the same argument as before the right hand sides must match.
    \end{itemize}
    This covers all the cases and thus we have shown that $R_1=R_2$, $p_1=p_2$
    and $q_1=q_2$. Coupled with the induction hypothesis, this means that $\pi=\pi'$.
\end{proof}

Note that the definition of $D$ relies on some properties of CCS specifically.
\begin{enumerate}
    \item We must have that $p \trans{a} p'$ leads to $p\not\equiv p'$. This is
          necessary so that the case-definitions are well defined, i.e. that
          they are mutually exclusive. This means that we can rely on
          $\equiv$-testing to determine if one side of the composition took
          a step or not.

          We should also note that this requirement means that we can actually
          remove the text ``and $\alpha=\tau$'' from the last case condition. To
          see why, note that the condition $q'\not\equiv q'' \land p'\not\equiv p''$
          (as implied by the word ``otherwise'') means that both must have taken
          a step simultaneously and communicated,  and therefore the only possible
          result action is indeed $\tau$. This means that the definition properly
          covers all cases.
% TODO: probably not needed...
%     \item The parallel operator needs to be commutative. Consider the process
%           $p = (a.0 + \bar{a}.0)$ and then consider $p \parallel p$. A
%           computation after one step of execution will be
% \[
%     (p\parallel p, p\parallel p \trans{\tau} 0 \parallel 0)
% \]
%           From this computation it is not possible to determine which side did
%           $a$ and which did $\bar{a}$. The commutativity of $\parallel$
%           means this is not really an issue (I think) as for any $p,q$ we can
%           consider $p\parallel q$ equal to $q\parallel p$, and we just pick
%           one side for the $a$ and the other for $\bar{a}$. However, when the
%           communication results in a composition of two distinct components,
%           then we can use the syntax of these components to deduce what were
%           the actions of each side.
    \item The only possible result of a communication is $\tau$, and $\tau$
          can never act as one partner of the communication.
\end{enumerate}

We now want to define quotient on \HMLpast-formulae such that a property of the
form
\[
    (p\parallel q, \pi) \vDash \phi  \quad\Leftrightarrow\quad
    (p, \mu_1) \vDash \phi/(q, \mu_2)
\]
where $(\mu_1,\mu_2) \in D(\pi)$. However, since we are dealing with sets of
decompositions, we need to quantify over these sets. It turns out that a
natural way that also gives a strong result is the following. Given that a composed
computation satisfies a formula, we can prove that one component of {\em every}
decomposition satisfies a formula quotiented with the other component,
\[
    (p\parallel q, \pi) \vDash \phi  \quad\Rightarrow\quad
    \forall (\mu_1,\mu_2) \in D(\pi) : (p, \mu_1) \vDash \phi/(q, \mu_2).
\]
On the other hand, to show the other direction, we need only one witness of a
decomposition that satisfies a quotiented formula to deduce that the composed
computation satisfies the original one,
\[
    \exists (\mu_1,\mu_2) \in D(\pi) : (p, \mu_1) \vDash \phi/(q, \mu_2)
    \quad\Rightarrow\quad
    (p\parallel q, \pi) \vDash \phi.
\]

Before defining the quotienting transformation we need define what $\vDash$ 
means with respect to stuttering computations.
We do this by extending \HMLpast{} to \HMLpp{} by adding
two operators.

\begin{definition}[Stuttering Hennessy Milner logic with past]
    \label{dfn:hmlpast}
    Let $\T=\langle P,A,\rightarrow \rangle$ be an LTS. The set $\HMLpp(A)$,
    or simply $\HMLpp$, of
    \emph{stuttering Hennessy-Milner logic formulae with past}
    is defined by the grammar
    \[
        \phi,\psi \,::=\, \true \alt \phi\land\psi
                                \alt \neg\phi
                                \alt \dmnd{\alpha} \phi
                                \alt \dmndback{\alpha} \phi
                                \alt \pdmnd{} \phi
                                \alt \pdmndback{} \phi
    \]
    where $i\in\mathbb{N}$ and $\alpha\in A_\tau$.
    We define the \emph{satisfaction relation} $\vDash^*\,\subseteq \C_\T^* \times \HMLpp$
    as the least relation that satisfies the following,
    \begin{itemize}
        \item $\rho\vDash^*\true$ for all $\rho\in\C_\T^*$,
        \item $\rho\vDash^*\phi\land\psi$ iff $\rho\vDash^*\phi$ and $\rho\vDash^*\psi$,
        \item $\rho\vDash^*\neg\phi$ iff not $\rho\vDash^*\phi$,
        \item $\rho\vDash^*\dmnd{\alpha}\phi$ iff for some
              $\rho'\in\C_\T^* : \rho\trans{\alpha}\rho'$ and $\rho'\vDash^*\phi$
        \item $\rho\vDash^*\dmndback{\alpha}\phi$ iff for some
              $\rho'\in\C_\T^* : \rho'\trans{\alpha}\rho$ and $\rho'\vDash^*\phi$
        \item $\rho\vDash^*\pdmnd{}\phi$ iff
              $\rho(p\ptrans{} p) \vDash^* \phi$ where $p=\last(\rho)$.
        \item $\rho\vDash^*\pdmndback{}\phi$ iff
              $\rho' \vDash^* \phi$ where $\rho = \rho'(p \ptrans{} p)$ for some $p$.
    \end{itemize}
    The satisfaction relation $\vDash^*\,\in P\times\HMLpp$ is defined by
    $p\vDash^*\phi$ if and only if $(p,\lambda)\vDash^* \phi$.
\end{definition}

\begin{remark}
    The satisfaction relations $\vDash^*$ and $\vDash$ coincide over $\C_\T \times \HMLpast$.
\end{remark}
% \paragraph{\bf Problem:} There is a problem here which makes this not well defined.
% Consider the processes $p = (a.c.0 + b.c.0)$ and $q = (\bar{a}.d.0 + \bar{b}.d.0)$.
% A computation after one step may look like this:
% \[
%     (p \parallel q, p\parallel q \trans{\tau} c.0 \parallel d.0)
% \]
% The problem here is that the above definition fails both of the computations
% \[
%     (p, p\trans{a}c.0) \quad\textrm{and}\quad (p, p\trans{b}c.0)
% \]
% are possible candidates for the left component. Possible solution: we extend
% the semantics of CCS to annotate $\tau$ actions resulting from communication
% with the actions that were performed by each side. (Would this solution perhaps
% also address 2 above, i.e. $\parallel$ would not need to be commutative?)
% Now the property we want is actually
% \[
%     (p\parallel q, \pi) \vDash^* \phi  \quad\Leftrightarrow\quad
%     \forall (\mu_1,\mu_2)\in D(\pi) : (p, \mu_1) \vDash^* \phi/(q, \mu_2).
% \]

% subsection decomposition_of_computations (end)

\subsection{Why are the stutters necessary?}

One may ask why we need to extend both computations and the logic to include the
notion of stuttering steps. The reason for doing so is to capture the information
about the interleaving order in component computations. This in turn is necessary because
the original logic can differentiate between different interleavings of parallel
processes.

For an example, let $p$ be a process that cannot perform an $a$ action, but
$p\trans{b} p'$ for some $p'$. Consider the computation $(a.0 \parallel p, \pi)$
where
\begin{equation}\label{eq:interleave1}
    \pi = a.0 \parallel p \trans{a} 0 \parallel p \trans{b} 0 \parallel p'
\end{equation}
Clearly this computation does {\bf not} satisfy the formula $\dmndback{a}\true$.

Another interleaving of the same parallel composition is the computation
$(a.0\parallel p, \pi')$ where
\begin{equation}\label{eq:interleave2}
    \pi' = a.0 \parallel p \trans{b} a.0 \parallel p' \trans{a} 0\parallel p'.
\end{equation}
This computation however does satisfy $\dmndback a \true$. Since the logic can
distinguish between different interleaving orders of a parallel computation, it
is vital to maintain information about interleaving order in our decomposition.
If the decomposition of the above computations only consider the actions contributed
by each component, this information is lost and both decompose to the same pair
of computations and we cannot reasonably expect to test if they satisfy the
formula $\dmndback a \true$ in a decompositional manner.

% section notes_to_be_structured_ (end)
